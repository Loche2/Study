# 优缺点



## 知识表示

|            | 优点                                       | 缺点                                                         | 应用/领域                                                    |
| ---------- | ------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 谓词逻辑   | 自然性、精准性、容易实现                   | 不能表示不确定性知识；形式过于自由，兼容性差                 | 自动问答系统；机器人行动规划系统；机器博弈系统；问题求解系统 |
| 产生式系统 | 自然性、模块性、有效性、清晰性             | 效率不高；不能表达结构性知识                                 | 自然性领域知识间关系不密切不存在结构关系；经验性及不确定性的知识，且相关领域中对这些知识没有严格、统一的理论；领域问题的求解过程可被表示为一系列相对独立的操作，且每个操作可被表示为一条或多条产生式规则 |
| 专家系统   | 第一次使用知识库、可信度，实现不确定性推理 | 知识获取瓶颈问题；规则“跷跷板”问题；知识动态化、知识更新问题 | 随着时代发展，人工建设专家系统的效率低、成本高，逐渐成为历史，但基于知识的人工智能方法仍然在不断进步；近几年来成为研究热点的知识图谱，某种程度上就可以看作是大规模的知识集合。 |
| 框架表示法 | 结构性、继承性、自然性                     |                                                              |                                                              |
| 语义网络   | 结构性、联想性、自索引性、自然性           | 非严格性、复杂性                                             |                                                              |



## 搜索求解

|              | 特征                                                         | 性能                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 盲目式搜索   | 没有启发信息的一种搜索形式；搜索过程中不使用与问题有关的经验信息 | 搜索效率低，耗费过多的计算空间与时间；不适合大空间的实际问题求解，可能带来组合爆炸 |
| 宽度优先搜索 | 属于图搜索方法；**新扩展的节点排在open表的末端**；当问题有解时，一定能找到解 | 方法与问题无关，具有通用性；效率较低                         |
| 深度优先搜索 | 一般不能保证找到最优解                                       | 当深度限制不合理时，可能找不到解，可以将算法改为可变深度限制；最坏情况时，搜索空间等同于穷举； |
| 等代价搜索   | 按预先设置的策略或已付出的代价进行搜索，没有利用搜索过程中的信息指导搜索 |                                                              |
| A算法        | 估价函数 :  $f (n) = g (n) + h (n)$；对$h(n)$无限制，虽提高了算法效率，但不能保证找到最优解；不合适的$h(n)$定义会导致算法找不到解 | 不完备（*它可能沿着一条无限的路径走下去而不回来做其他的选择尝试，因此无法找到最佳路径这一答案。*）；不最优 |
| A*算法       | 采用$h^*(n)$的下界$h(n)$为启发函数的A算法，称为A\*算法； A* 算法要求$h(n)\le h^*(n)$。它表示某种偏于保守的估计。 | 如果算法有解，A\*算法一定能够找到最优的解答;一般说来，在满足$h(n)≤h^*(n)$的前提下，$h(n)$的比重越大越好，$h(n)$的比重越大表示启发性越强。 |



## 智能计算

|            | 优点                                                         | 缺点                                                         |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 遗传算法   | 可以证明遗传算法在概率上会收敛到最优解                       | 但并不意味着每一次求解一定能得到最优解                       |
| 粒子群算法 | 简单易实现；收敛速度快；粒子具有记忆性                       | 缺乏速度的自适应调节，容易陷入局部最优，可能导致收敛精度低或者不收敛；标准粒子群算法不能有效求解离散及组合优化问题；参数难以确定，对不同的问题，需选择合适的参数来达到最优效果 |
| 蚁群算法   | 蚁群算法与其他启发式算法相比，在求解性能上具有很强的鲁棒性，搜索能力较强；蚁群算法是一种基于种群的算法，具有本质并行性，易于并行实现；蚁群算法很容易与其他算法，如：遗传算法、粒子群算法结合，以改善算法性能 | 如果初始化参数设置不当，会导致求解速度很慢且所得解的质量特别差；基本蚁群算法即无改进的蚁群算法，计算量大，求解所需时间较长 |



## 机器学习

|      | 优点                                                         | 缺点                                                         |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| KNN  | 算法简单，理论成熟，既可以用来做分类也可以用来做回归；可用于非线性分类；没有明显的训练过程，而是在程序开始运行时，把数据集加载到内存后，不需要进行训练，直接进行预测，所以训练时间复杂度为0；由于KNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属的类别，因此对于类域的交叉或重叠较多的待分类样本集来说，KNN方法较其他方法更为适合；该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量比较小的类域采用这种算法比较容易产生误分类情况。 | 需要算每个测试点与训练集的距离，当训练集较大时，计算量相当大，时间复杂度高，特别是特征数量比较大的时候；需要大量的内存，空间复杂度高；样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少），对稀有类别的预测准确度低；是lazy learning方法，基本上不学习，导致预测时速度比起逻辑回归之类的算法慢。 |
| ID3  | 只需对训练实例进行较好地标注，就能进行学习，从一类无序、无规则事物(概念)中推理出分类规则；分类模型是树状结构，简单直观，可将决策树中到达每个叶结点的路径转换为IF-THEN形式的分类规则，比较符合人类的理解方式。 | 信息增益偏好取值多的属性；可能会受噪声或小样本影响，易出现过拟合问题；无法处理连续值的属性；无法处理属性值不完整的训练数据 |



## 人工神经网络